{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "22ce6685-184c-4eaa-a1c2-0b8c9f99ad08",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split,GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer,TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score,f1_score,confusion_matrix,ConfusionMatrixDisplay,RocCurveDisplay,classification_report,recall_score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fd8e2a5-07a2-48b3-bcd8-ceb5e8b38c58",
   "metadata": {},
   "source": [
    "## Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "29fd8e53-b00e-43ac-9edf-6602944b317c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>cuisine</th>\n",
       "      <th>ingredients</th>\n",
       "      <th>ingredient_text</th>\n",
       "      <th>ingredient_clean_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10259</td>\n",
       "      <td>greek</td>\n",
       "      <td>['romaine lettuce', 'black olives', 'grape tom...</td>\n",
       "      <td>romaine lettuce black olives grape tomatoes ga...</td>\n",
       "      <td>romaine lettuce black olive grape tomato garli...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>25693</td>\n",
       "      <td>southern_us</td>\n",
       "      <td>['plain flour', 'ground pepper', 'salt', 'toma...</td>\n",
       "      <td>plain flour ground pepper salt tomatoes ground...</td>\n",
       "      <td>plain flour ground pepper salt tomato ground b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20130</td>\n",
       "      <td>filipino</td>\n",
       "      <td>['eggs', 'pepper', 'salt', 'mayonaise', 'cooki...</td>\n",
       "      <td>eggs pepper salt mayonaise cooking oil green c...</td>\n",
       "      <td>egg pepper salt mayonaise cook oil green chili...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>22213</td>\n",
       "      <td>indian</td>\n",
       "      <td>['water', 'vegetable oil', 'wheat', 'salt']</td>\n",
       "      <td>water vegetable oil wheat salt</td>\n",
       "      <td>water vegetable oil wheat salt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13162</td>\n",
       "      <td>indian</td>\n",
       "      <td>['black pepper', 'shallots', 'cornflour', 'cay...</td>\n",
       "      <td>black pepper shallots cornflour cayenne pepper...</td>\n",
       "      <td>black pepper shallot cornflour cayenne pepper ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id      cuisine                                        ingredients  \\\n",
       "0  10259        greek  ['romaine lettuce', 'black olives', 'grape tom...   \n",
       "1  25693  southern_us  ['plain flour', 'ground pepper', 'salt', 'toma...   \n",
       "2  20130     filipino  ['eggs', 'pepper', 'salt', 'mayonaise', 'cooki...   \n",
       "3  22213       indian        ['water', 'vegetable oil', 'wheat', 'salt']   \n",
       "4  13162       indian  ['black pepper', 'shallots', 'cornflour', 'cay...   \n",
       "\n",
       "                                     ingredient_text  \\\n",
       "0  romaine lettuce black olives grape tomatoes ga...   \n",
       "1  plain flour ground pepper salt tomatoes ground...   \n",
       "2  eggs pepper salt mayonaise cooking oil green c...   \n",
       "3                     water vegetable oil wheat salt   \n",
       "4  black pepper shallots cornflour cayenne pepper...   \n",
       "\n",
       "                               ingredient_clean_text  \n",
       "0  romaine lettuce black olive grape tomato garli...  \n",
       "1  plain flour ground pepper salt tomato ground b...  \n",
       "2  egg pepper salt mayonaise cook oil green chili...  \n",
       "3                     water vegetable oil wheat salt  \n",
       "4  black pepper shallot cornflour cayenne pepper ...  "
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Load data\n",
    "data = pd.read_csv('../data/processed_text.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57a311b4-036d-4b0e-85bc-4676fb704584",
   "metadata": {},
   "source": [
    "## Features and Target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "8b822827-4d77-4571-9cf2-6d5d68efbeff",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'greek': 0, 'southern_us': 1, 'filipino': 2, 'indian': 3, 'jamaican': 4, 'spanish': 5, 'italian': 6, 'mexican': 7, 'chinese': 8, 'british': 9, 'thai': 10, 'vietnamese': 11, 'cajun_creole': 12, 'brazilian': 13, 'french': 14, 'japanese': 15, 'irish': 16, 'korean': 17, 'moroccan': 18, 'russian': 19}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "X = data['ingredient_clean_text']\n",
    "\n",
    "cuisines = ['greek', 'southern_us', 'filipino', 'indian', 'jamaican',\n",
    "            'spanish', 'italian', 'mexican', 'chinese', 'british', 'thai',\n",
    "            'vietnamese', 'cajun_creole', 'brazilian', 'french', 'japanese',\n",
    "            'irish', 'korean', 'moroccan', 'russian']\n",
    "\n",
    "\n",
    "cuisine_mapping = {cuisine: i for i, cuisine in enumerate(cuisines)}\n",
    "\n",
    "print(cuisine_mapping)\n",
    "y = data['cuisine'].map(cuisine_mapping)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bad1193a-a5e9-4b73-b8fe-858df3f3467c",
   "metadata": {},
   "source": [
    "## Baseline model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "43d3caee-5c87-40bd-b22c-2339fc917373",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "cuisine\n",
       "6     0.197063\n",
       "7     0.161865\n",
       "1     0.108614\n",
       "3     0.075502\n",
       "8     0.067205\n",
       "14    0.066526\n",
       "12    0.038870\n",
       "10    0.038694\n",
       "15    0.035777\n",
       "0     0.029542\n",
       "5     0.024865\n",
       "17    0.020868\n",
       "11    0.020742\n",
       "18    0.020642\n",
       "9     0.020214\n",
       "2     0.018982\n",
       "16    0.016770\n",
       "4     0.013225\n",
       "19    0.012294\n",
       "13    0.011741\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "y.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "cc047145-3b2c-4f9d-8c56-94605ef4f5c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((29830,), (29830,), (9944,), (9944,))"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Train-test Split\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,random_state=42,stratify=y)\n",
    "X_train.shape,y_train.shape,X_test.shape,y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87908b9c-b098-4311-85d7-185dc1a8f2e7",
   "metadata": {},
   "source": [
    "## Logistic Regression with TF-IDF Vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "d2dfc481-518b-4a73-a0f3-28aba5a619da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 0.82\n",
      "Testing Accuracy: 0.78\n",
      "Training Misclassification Rate: 0.18\n",
      "Testing Misclassification Rate: 0.22\n",
      "Recall (Weighted Average): 0.78\n",
      "F1 Score (Weighted Average): 0.77\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.66      0.71       294\n",
      "           1       0.69      0.82      0.75      1080\n",
      "           2       0.72      0.54      0.62       189\n",
      "           3       0.86      0.90      0.88       751\n",
      "           4       0.90      0.66      0.76       131\n",
      "           5       0.67      0.44      0.53       247\n",
      "           6       0.78      0.90      0.84      1960\n",
      "           7       0.90      0.92      0.91      1610\n",
      "           8       0.78      0.86      0.82       668\n",
      "           9       0.64      0.41      0.50       201\n",
      "          10       0.78      0.78      0.78       385\n",
      "          11       0.77      0.54      0.64       206\n",
      "          12       0.76      0.70      0.73       386\n",
      "          13       0.74      0.43      0.54       117\n",
      "          14       0.62      0.62      0.62       662\n",
      "          15       0.83      0.68      0.75       356\n",
      "          16       0.69      0.45      0.54       167\n",
      "          17       0.87      0.70      0.78       207\n",
      "          18       0.82      0.77      0.79       205\n",
      "          19       0.68      0.37      0.48       122\n",
      "\n",
      "    accuracy                           0.78      9944\n",
      "   macro avg       0.76      0.66      0.70      9944\n",
      "weighted avg       0.78      0.78      0.77      9944\n",
      "\n"
     ]
    }
   ],
   "source": [
    "logr_tfidf_pipeline =Pipeline(\n",
    "    [\n",
    "        ('tf-idf',TfidfVectorizer()),\n",
    "        ('logr',LogisticRegression(random_state=42,max_iter=1000))\n",
    "    ]\n",
    "    \n",
    ")\n",
    "\n",
    "\n",
    "logr_tfidf_pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test data\n",
    "predictions = logr_tfidf_pipeline.predict(X_test)\n",
    "\n",
    "# Predict on the test data\n",
    "predictions = logr_tfidf_pipeline.predict(X_test)\n",
    "\n",
    "# Calculate accuracy on training and test set\n",
    "logr_train_accuracy = logr_tfidf_pipeline.score(X_train, y_train)\n",
    "logr_test_accuracy = logr_tfidf_pipeline.score(X_test, y_test)\n",
    "\n",
    "# Calculate misclassification rates\n",
    "logr_train_misclassification_rate = 1 - logr_train_accuracy\n",
    "logr_test_misclassification_rate = 1 - logr_test_accuracy\n",
    "\n",
    "print(f'Training Accuracy: {logr_train_accuracy:.2f}')\n",
    "print(f'Testing Accuracy: {logr_test_accuracy:.2f}')\n",
    "print(f'Training Misclassification Rate: {logr_train_misclassification_rate:.2f}')\n",
    "print(f'Testing Misclassification Rate: {logr_test_misclassification_rate:.2f}')\n",
    "# Calculate recall and F1 scores\n",
    "logr_recall = recall_score(y_test, predictions, average='weighted')\n",
    "logr_f1 = f1_score(y_test, predictions, average='weighted')\n",
    "\n",
    "print(f'Recall (Weighted Average): {logr_recall:.2f}')\n",
    "print(f'F1 Score (Weighted Average): {logr_f1:.2f}')\n",
    "\n",
    "# Display classification report for detailed per-class metrics\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c69c0acf-95b3-4b5f-8ecc-dc79bf609f34",
   "metadata": {},
   "source": [
    "## Logistic Regression with Count Vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "4bc47404-5915-43bd-860a-2250b8ce63b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 0.86\n",
      "Testing Accuracy: 0.78\n",
      "Training Misclassification Rate: 0.14\n",
      "Testing Misclassification Rate: 0.22\n",
      "Recall (Weighted Average): 0.78\n",
      "F1 Score (Weighted Average): 0.78\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.71      0.74       294\n",
      "           1       0.72      0.80      0.76      1080\n",
      "           2       0.66      0.59      0.62       189\n",
      "           3       0.85      0.88      0.87       751\n",
      "           4       0.82      0.69      0.75       131\n",
      "           5       0.63      0.48      0.55       247\n",
      "           6       0.81      0.88      0.84      1960\n",
      "           7       0.90      0.92      0.91      1610\n",
      "           8       0.81      0.83      0.82       668\n",
      "           9       0.55      0.48      0.52       201\n",
      "          10       0.77      0.78      0.77       385\n",
      "          11       0.68      0.56      0.62       206\n",
      "          12       0.75      0.68      0.71       386\n",
      "          13       0.68      0.50      0.58       117\n",
      "          14       0.64      0.64      0.64       662\n",
      "          15       0.79      0.71      0.75       356\n",
      "          16       0.59      0.53      0.56       167\n",
      "          17       0.86      0.78      0.82       207\n",
      "          18       0.81      0.78      0.79       205\n",
      "          19       0.60      0.48      0.53       122\n",
      "\n",
      "    accuracy                           0.78      9944\n",
      "   macro avg       0.73      0.68      0.71      9944\n",
      "weighted avg       0.78      0.78      0.78      9944\n",
      "\n"
     ]
    }
   ],
   "source": [
    "logr_cvec_pipeline =Pipeline(\n",
    "    [\n",
    "        ('cvec',CountVectorizer()),\n",
    "        ('logr',LogisticRegression(random_state=42,max_iter=1000))\n",
    "    ]\n",
    "    \n",
    ")\n",
    "\n",
    "\n",
    "logr_cvec_pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test data\n",
    "predictions = logr_cvec_pipeline.predict(X_test)\n",
    "\n",
    "# Calculate accuracy on training and test set\n",
    "logr_train_accuracy = logr_cvec_pipeline.score(X_train, y_train)\n",
    "logr_test_accuracy = logr_cvec_pipeline.score(X_test, y_test)\n",
    "\n",
    "# Calculate misclassification rates\n",
    "logr_train_misclassification_rate = 1 - logr_train_accuracy\n",
    "logr_test_misclassification_rate = 1 - logr_test_accuracy\n",
    "\n",
    "print(f'Training Accuracy: {logr_train_accuracy:.2f}')\n",
    "print(f'Testing Accuracy: {logr_test_accuracy:.2f}')\n",
    "print(f'Training Misclassification Rate: {logr_train_misclassification_rate:.2f}')\n",
    "print(f'Testing Misclassification Rate: {logr_test_misclassification_rate:.2f}')\n",
    "# Calculate recall and F1 scores\n",
    "logr_recall = recall_score(y_test, predictions, average='weighted')\n",
    "logr_f1 = f1_score(y_test, predictions, average='weighted')\n",
    "\n",
    "print(f'Recall (Weighted Average): {logr_recall:.2f}')\n",
    "print(f'F1 Score (Weighted Average): {logr_f1:.2f}')\n",
    "\n",
    "# Display classification report for detailed per-class metrics\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, predictions))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5550e48e-ae98-4c86-83fb-6df188b0c622",
   "metadata": {},
   "source": [
    "## Grid Search Logistic Regression with Count Vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "ff53401d-4571-4724-8661-97aba84c5439",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/joblib/externals/loky/process_executor.py:752: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Best parameters:{'cvec__max_df': 0.85, 'cvec__max_features': None, 'cvec__min_df': 2, 'cvec__ngram_range': (1, 1), 'logr__C': 1.0, 'logr__penalty': 'l2', 'logr__solver': 'lbfgs'}\n",
      " Best score:0.7745893395910157\n"
     ]
    }
   ],
   "source": [
    "##Model \n",
    "#Logistic Regression\n",
    "log_pipeline = Pipeline(\n",
    "    [\n",
    "        ('cvec',CountVectorizer()),\n",
    "        ('logr',LogisticRegression(random_state=42,max_iter=1000))\n",
    "    ]\n",
    "    \n",
    ")\n",
    "params_list ={\n",
    "\n",
    "    'cvec__ngram_range': [(1, 1), (1, 2)],  # Unigrams and bigrams\n",
    "    'cvec__max_df': [ 0.85, 1.0],      # Ignore very frequent words\n",
    "    'cvec__min_df': [1, 2],              # Ignore very infrequent words\n",
    "    'cvec__max_features': [None, 5000],  # Limit on the number of features\n",
    "\n",
    "    'logr__C': [0.01, 0.1, 1.0],        # Regularization strength\n",
    "    'logr__penalty': ['l2'],                # L2 regularization (Ridge)\n",
    "    'logr__solver': ['lbfgs']  # Solvers suitable for small datase\n",
    "}\n",
    "gs_logr = GridSearchCV(log_pipeline,param_grid=params_list,n_jobs=-1)\n",
    "gs_logr.fit(X_train,y_train)\n",
    "print(f' Best parameters:{gs_logr.best_params_}')\n",
    "print(f' Best score:{gs_logr.best_score_}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "0d528bae-28fd-4040-b492-dba2dc7442e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 0.86\n",
      "Testing Accuracy: 0.78\n",
      "Training Misclassification Rate: 0.14\n",
      "Testing Misclassification Rate: 0.22\n",
      "Recall (Weighted Average): 0.78\n",
      "F1 Score (Weighted Average): 0.78\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.70      0.73       294\n",
      "           1       0.72      0.80      0.76      1080\n",
      "           2       0.65      0.58      0.62       189\n",
      "           3       0.85      0.88      0.86       751\n",
      "           4       0.82      0.69      0.75       131\n",
      "           5       0.63      0.48      0.55       247\n",
      "           6       0.81      0.88      0.84      1960\n",
      "           7       0.90      0.92      0.91      1610\n",
      "           8       0.81      0.82      0.82       668\n",
      "           9       0.56      0.48      0.51       201\n",
      "          10       0.77      0.78      0.77       385\n",
      "          11       0.68      0.57      0.62       206\n",
      "          12       0.75      0.68      0.71       386\n",
      "          13       0.69      0.50      0.58       117\n",
      "          14       0.64      0.64      0.64       662\n",
      "          15       0.78      0.71      0.74       356\n",
      "          16       0.60      0.53      0.57       167\n",
      "          17       0.86      0.78      0.82       207\n",
      "          18       0.82      0.78      0.80       205\n",
      "          19       0.61      0.48      0.54       122\n",
      "\n",
      "    accuracy                           0.78      9944\n",
      "   macro avg       0.73      0.68      0.71      9944\n",
      "weighted avg       0.78      0.78      0.78      9944\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Predict on the test data\n",
    "predictions = gs_logr.predict(X_test)\n",
    "\n",
    "# Predict on the test data\n",
    "predictions = gs_logr.predict(X_test)\n",
    "\n",
    "# Calculate accuracy on training and test set\n",
    "logr_train_accuracy = gs_logr.score(X_train, y_train)\n",
    "logr_test_accuracy = gs_logr.score(X_test, y_test)\n",
    "\n",
    "# Calculate misclassification rates\n",
    "logr_train_misclassification_rate = 1 - logr_train_accuracy\n",
    "logr_test_misclassification_rate = 1 - logr_test_accuracy\n",
    "\n",
    "print(f'Training Accuracy: {logr_train_accuracy:.2f}')\n",
    "print(f'Testing Accuracy: {logr_test_accuracy:.2f}')\n",
    "print(f'Training Misclassification Rate: {logr_train_misclassification_rate:.2f}')\n",
    "print(f'Testing Misclassification Rate: {logr_test_misclassification_rate:.2f}')\n",
    "# Calculate recall and F1 scores\n",
    "logr_recall = recall_score(y_test, predictions, average='weighted')\n",
    "logr_f1 = f1_score(y_test, predictions, average='weighted')\n",
    "\n",
    "print(f'Recall (Weighted Average): {logr_recall:.2f}')\n",
    "print(f'F1 Score (Weighted Average): {logr_f1:.2f}')\n",
    "\n",
    "# Display classification report for detailed per-class metrics\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1a0f549-82b7-4c5c-bb80-94c454cca537",
   "metadata": {},
   "source": [
    "## XBBoost with TF-IDF Vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "3753bdd9-8b57-49cf-84e7-fe6314dd0c64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7366074421723098\n",
      "0.7201327433628318\n"
     ]
    }
   ],
   "source": [
    "#XG_Boost\n",
    "\n",
    "xbg_pipeline =Pipeline(\n",
    "    [\n",
    "        ('tf-idf',TfidfVectorizer()),\n",
    "        ('xgb',XGBClassifier(n_estimators = 100,\n",
    "                   max_depth = 1))\n",
    "    ]\n",
    "    \n",
    ")\n",
    "\n",
    "xbg_pipeline.fit(X_train.values, y_train.values)\n",
    "\n",
    "print(xbg_pipeline.score(X_train, y_train))\n",
    "print(xbg_pipeline.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "84048095-bc92-4f9d-8c8f-334508c1d55b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 0.74\n",
      "Testing Accuracy: 0.72\n",
      "Training Misclassification Rate: 0.26\n",
      "Testing Misclassification Rate: 0.28\n",
      "Recall (Weighted Average): 0.72\n",
      "F1 Score (Weighted Average): 0.71\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.60      0.67       294\n",
      "           1       0.57      0.76      0.65      1080\n",
      "           2       0.67      0.35      0.46       189\n",
      "           3       0.85      0.85      0.85       751\n",
      "           4       0.84      0.62      0.71       131\n",
      "           5       0.76      0.30      0.43       247\n",
      "           6       0.66      0.88      0.75      1960\n",
      "           7       0.87      0.89      0.88      1610\n",
      "           8       0.75      0.82      0.78       668\n",
      "           9       0.65      0.17      0.27       201\n",
      "          10       0.75      0.69      0.72       385\n",
      "          11       0.63      0.49      0.55       206\n",
      "          12       0.80      0.68      0.73       386\n",
      "          13       0.67      0.35      0.46       117\n",
      "          14       0.57      0.47      0.52       662\n",
      "          15       0.90      0.60      0.72       356\n",
      "          16       0.60      0.35      0.44       167\n",
      "          17       0.81      0.66      0.73       207\n",
      "          18       0.84      0.68      0.75       205\n",
      "          19       0.68      0.32      0.44       122\n",
      "\n",
      "    accuracy                           0.72      9944\n",
      "   macro avg       0.73      0.58      0.63      9944\n",
      "weighted avg       0.73      0.72      0.71      9944\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Predict on the test data\n",
    "predictions = xbg_pipeline.predict(X_test)\n",
    "\n",
    "# Predict on the test data\n",
    "predictions = xbg_pipeline.predict(X_test)\n",
    "\n",
    "# Calculate accuracy on training and test set\n",
    "logr_train_accuracy = xbg_pipeline.score(X_train, y_train)\n",
    "logr_test_accuracy = xbg_pipeline.score(X_test, y_test)\n",
    "\n",
    "# Calculate misclassification rates\n",
    "logr_train_misclassification_rate = 1 - logr_train_accuracy\n",
    "logr_test_misclassification_rate = 1 - logr_test_accuracy\n",
    "\n",
    "print(f'Training Accuracy: {logr_train_accuracy:.2f}')\n",
    "print(f'Testing Accuracy: {logr_test_accuracy:.2f}')\n",
    "print(f'Training Misclassification Rate: {logr_train_misclassification_rate:.2f}')\n",
    "print(f'Testing Misclassification Rate: {logr_test_misclassification_rate:.2f}')\n",
    "# Calculate recall and F1 scores\n",
    "logr_recall = recall_score(y_test, predictions, average='weighted')\n",
    "logr_f1 = f1_score(y_test, predictions, average='weighted')\n",
    "\n",
    "print(f'Recall (Weighted Average): {logr_recall:.2f}')\n",
    "print(f'F1 Score (Weighted Average): {logr_f1:.2f}')\n",
    "\n",
    "# Display classification report for detailed per-class metrics\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f55a4fd-c088-480f-a59d-f99757a92046",
   "metadata": {},
   "source": [
    "## Grid Search XBBoost with TF-IDF Vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "4bfe373e-c6f6-4c06-a78a-682e7d40ff0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'tf-idf__max_df': 0.75, 'tf-idf__ngram_range': (1, 2), 'xgb__max_depth': 3, 'xgb__n_estimators': 100}\n",
      "Best cross-validation score: 0.76\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Define the parameter grid\n",
    "param_grid = {\n",
    "    'tf-idf__max_df': [0.5, 0.75],\n",
    "    'tf-idf__ngram_range': [(1, 1), (1, 2)],  # unigrams or bigrams\n",
    "    'xgb__n_estimators': [50, 100],\n",
    "    'xgb__max_depth': [1, 3]\n",
    "}\n",
    "\n",
    "\n",
    "# Setup the grid search\n",
    "grid_search = GridSearchCV(xbg_pipeline,param_grid= param_grid, cv=5, n_jobs=-1)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Best model and parameters\n",
    "print(\"Best parameters:\", grid_search.best_params_)\n",
    "print(\"Best cross-validation score: {:.2f}\".format(grid_search.best_score_))\n",
    "\n",
    "# Predict and evaluate the model\n",
    "predictions = grid_search.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "c4f5d433-74f0-4de1-9910-847d30e996f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 0.86\n",
      "Testing Accuracy: 0.77\n",
      "Training Misclassification Rate: 0.14\n",
      "Testing Misclassification Rate: 0.23\n",
      "Recall (Weighted Average): 0.77\n",
      "F1 Score (Weighted Average): 0.76\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.68      0.73       294\n",
      "           1       0.66      0.80      0.72      1080\n",
      "           2       0.69      0.47      0.56       189\n",
      "           3       0.86      0.90      0.88       751\n",
      "           4       0.88      0.66      0.75       131\n",
      "           5       0.72      0.43      0.54       247\n",
      "           6       0.75      0.89      0.81      1960\n",
      "           7       0.89      0.91      0.90      1610\n",
      "           8       0.79      0.83      0.81       668\n",
      "           9       0.62      0.37      0.46       201\n",
      "          10       0.79      0.78      0.78       385\n",
      "          11       0.74      0.60      0.66       206\n",
      "          12       0.80      0.70      0.75       386\n",
      "          13       0.79      0.50      0.61       117\n",
      "          14       0.60      0.57      0.58       662\n",
      "          15       0.83      0.66      0.74       356\n",
      "          16       0.69      0.43      0.53       167\n",
      "          17       0.84      0.72      0.77       207\n",
      "          18       0.82      0.74      0.77       205\n",
      "          19       0.60      0.39      0.48       122\n",
      "\n",
      "    accuracy                           0.77      9944\n",
      "   macro avg       0.76      0.65      0.69      9944\n",
      "weighted avg       0.77      0.77      0.76      9944\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Predict on the test data\n",
    "predictions = grid_search.predict(X_test)\n",
    "\n",
    "# Predict on the test data\n",
    "predictions = grid_search.predict(X_test)\n",
    "\n",
    "# Calculate accuracy on training and test set\n",
    "logr_train_accuracy = grid_search.score(X_train, y_train)\n",
    "logr_test_accuracy = grid_search.score(X_test, y_test)\n",
    "\n",
    "# Calculate misclassification rates\n",
    "logr_train_misclassification_rate = 1 - logr_train_accuracy\n",
    "logr_test_misclassification_rate = 1 - logr_test_accuracy\n",
    "\n",
    "print(f'Training Accuracy: {logr_train_accuracy:.2f}')\n",
    "print(f'Testing Accuracy: {logr_test_accuracy:.2f}')\n",
    "print(f'Training Misclassification Rate: {logr_train_misclassification_rate:.2f}')\n",
    "print(f'Testing Misclassification Rate: {logr_test_misclassification_rate:.2f}')\n",
    "# Calculate recall and F1 scores\n",
    "logr_recall = recall_score(y_test, predictions, average='weighted')\n",
    "logr_f1 = f1_score(y_test, predictions, average='weighted')\n",
    "\n",
    "print(f'Recall (Weighted Average): {logr_recall:.2f}')\n",
    "print(f'F1 Score (Weighted Average): {logr_f1:.2f}')\n",
    "\n",
    "# Display classification report for detailed per-class metrics\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12cee606-9766-42dd-a711-3ad20ba3d764",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "19334466-24f4-406a-8d43-4e05f9ed6367",
   "metadata": {},
   "source": [
    "## Predictions on Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "85311412-6543-4299-b00a-e168dfa7e985",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Predictions on test set\n",
    "test = pd.read_csv('../data/processed_text_test.csv')\n",
    "test.head()\n",
    "X_test = test['ingredient_clean_text'] \n",
    "predictions = logr_cvec_pipeline.predict(X_test)\n",
    "\n",
    "#  DataFrame with the required format\n",
    "submission = pd.DataFrame({\n",
    "    'id': test['id'],      \n",
    "    'cuisine': predictions       \n",
    "})\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "submission.to_csv('../data/submission.csv', index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "17f8a3bf-bd20-421c-9051-81eaca5bcef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = grid_search.predict(X_test)\n",
    "\n",
    "#  DataFrame with the required format\n",
    "submission = pd.DataFrame({\n",
    "    'id': test['id'],      \n",
    "    'cuisine': predictions       \n",
    "})\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "submission.to_csv('../data/submission.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17eb98ab-7490-4858-8581-f17733f7727a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
